---
title: MinerUæœåŠ¡éƒ¨ç½²
author: Axellance
date: 2025-09-07
layout: post
category: è½¯ä»¶å¼€å‘, docker
tags: [è½¯ä»¶å¼€å‘,docker]
mermaid: true
---

## MinerUæœåŠ¡éƒ¨ç½²

MinerUæ˜¯ä¸€æ¬¾ç”±OpenDataLabç ”å‘ï¼Œå°†PDFæˆ–å›¾ç‰‡è½¬æ¢ä¸ºæœºå™¨å¯è¯»æ ¼å¼ï¼ˆå¦‚Markdownã€jsonï¼‰çš„å·¥å…·ï¼Œå¯ä»¥åœ¨å¾ˆå¤šé¡¹ç›®ä¸­ä½œä¸ºOCRæœåŠ¡è¿›è¡Œé›†æˆï¼Œå¤§å¤§æé«˜å¼€å‘è¿‡ç¨‹ä¸­æå–pdfæ‰«æä»¶ã€å›¾ç‰‡ä¸­ä¿¡æ¯çš„æ•ˆç‡ã€‚

æ„Ÿå…´è¶£çš„æœ‹å‹å¯ä»¥å…ˆåœ¨çº¿ä½“éªŒä¸‹MinerUæä¾›çš„å®˜æ–¹æ¥å£[MinerU-å…è´¹å…¨èƒ½çš„æ–‡æ¡£è§£æç¥å™¨](https://mineru.net/OpenSourceTools/Extractor)ã€‚åŒæ—¶ï¼ŒMinerUæä¾›äº†ä¾¿æ·çš„éƒ¨ç½²æ–¹å¼ï¼Œæœ‰åŠ©äºå¿«é€Ÿæ­å»ºç¯å¢ƒå¹¶è§£å†³ä¸€äº›ä»¤äººå¤´ç–¼çš„ç¯å¢ƒå…¼å®¹é—®é¢˜ï¼Œå¯ä»¥å¾ˆé«˜æ•ˆåœ°åœ¨å†…ç½‘å’Œç¦»çº¿ç¯å¢ƒä¸­éƒ¨ç½²æœåŠ¡ã€‚

è¿™æ˜¯å®˜æ–¹æä¾›çš„ä¸€ä¸ªæŠ€æœ¯è¯´æ˜å’Œé…ç½®è¦æ±‚è¡¨æ ¼ï¼Œå¯ä»¥å…ˆåšäº›ç®€å•äº†è§£ï¼š

| ç‰¹æ€§         | pipeline                                    | vlm-transformers             | vlm-sglang                 |
| ------------ | ------------------------------------------- | ---------------------------- | -------------------------- |
| æ“ä½œç³»ç»Ÿ     | Linux / Windows / macOS                     | Linux / Windows              | Linux / Windows (via WSL2) |
| CPUæ¨ç†æ”¯æŒ  | æ”¯æŒ                                        | ä¸æ”¯æŒ                              | åŒå‰ |
| GPUè¦æ±‚      | TuringåŠä»¥åæ¶æ„ï¼Œ6Gæ˜¾å­˜ä»¥ä¸Šæˆ–Apple Silicon | TuringåŠä»¥åæ¶æ„ï¼Œ8Gæ˜¾å­˜ä»¥ä¸Š | åŒå‰ |
| å†…å­˜è¦æ±‚     | æœ€ä½16Gä»¥ä¸Šï¼Œæ¨è32Gä»¥ä¸Š                    | åŒå‰ | åŒå‰ |
| ç£ç›˜ç©ºé—´è¦æ±‚ | 20Gä»¥ä¸Šï¼Œæ¨èä½¿ç”¨SSD                        |                              | åŒå‰ |
| Pythonç‰ˆæœ¬   | 3.10-3.13                                   |                              | åŒå‰ |

### 

### 1.ä½¿ç”¨Dockerfileæ„å»ºé•œåƒ

é¦–å…ˆä¸‹è½½Dockerfileæ–‡ä»¶ï¼š

```shell
wget https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/docker/china/Dockerfile
```

æˆ‘åœ¨æ„å»ºé•œåƒè¿‡ç¨‹ä¸­é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œæ‰€ä»¥å¯¹åŸæ¥äº†Dockerfileæ–‡ä»¶åšäº†å‡ å¤„ä¿®æ”¹ï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```dockerfile
# Use DaoCloud mirrored sglang image for China region
# FROM local/sglang:cu126
# For blackwell GPU, use the following line instead:
# ä¿®æ”¹1ï¼šä½¿ç”¨docker desktopæ‹‰å–è¿™ä¸ªåŸºç¡€é•œåƒï¼Œæˆ‘ç›´æ¥æ‹‰å–äº†docker.ioä¸Šçš„åŸºç¡€é•œåƒ
# FROM docker.m.daocloud.io/lmsysorg/sglang:v0.4.9.post6-cu128-b200

# Use the official sglang image
FROM lmsysorg/sglang:v0.4.9.post6-cu126
# For blackwell GPU, use the following line instead:
# FROM lmsysorg/sglang:v0.4.9.post6-cu128-b200

# Install libgl for opencv support & Noto fonts for Chinese characters
# ä¿®æ”¹2ï¼šç”±äºfonts-noto-coreç­‰å‡ ä¸ªå­—ä½“åŒ…å¤ªå¤§ï¼Œä»ubuntuå®˜æ–¹é•œåƒç«™ä¸‹è½½å¯èƒ½ä¼šå¯¼è‡´ä¸­æ–­ï¼Œæ‰€ä»¥ç›´æ¥æ›¿æ¢ä¸ºé˜¿é‡Œæº
RUN sed -i 's|http://.*.ubuntu.com|http://mirrors.aliyun.com|g' /etc/apt/sources.list && \
    apt-get update && \
    apt-get install -y \
        fonts-noto-core \
        fonts-noto-cjk \
        fontconfig \
        libgl1 && \
    fc-cache -fv && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

# Install mineru latest
RUN python3 -m pip install -U 'mineru[core]' -i https://mirrors.aliyun.com/pypi/simple --break-system-packages && \
    python3 -m pip cache purge

# Download models and update the configuration file
RUN /bin/bash -c "mineru-models-download -s modelscope -m all"

# Set the entry point to activate the virtual environment and run the command line tool
ENTRYPOINT ["/bin/bash", "-c", "export MINERU_MODEL_SOURCE=local && exec \"$@\"", "--"]
```

ä½¿ç”¨æˆ‘ä¿®æ”¹åçš„Dockerfileæ–‡ä»¶åº”è¯¥å¯ä»¥æ­£å¸¸æ„å»ºé•œåƒï¼Œå‘½ä»¤å¦‚ä¸‹ï¼š

```shell
docker build -t mineru-sglang:latest -f Dockerfile .
```

ç”±äºé•œåƒè¿‡å¤§ï¼Œè¶è¿™ä¸ªæ—¶å€™å¯ä»¥æµ…æµ…æ‘¸ä¸€ä¼šå„¿ğŸŸã€‚

è¿™é‡Œæœ‰ä¸€ç‚¹é—®é¢˜ï¼Œä¸çŸ¥é“å¤§å®¶æ˜¯å¦æ³¨æ„åˆ°äº†ã€‚ç›´æ¥ä»docker.ioæ‹‰å–åŸºç¡€é•œåƒï¼Œè¿™å¹¶ä¸æ˜¯ä¸ªå¥½çš„è§£å†³åŠæ³•ï¼Œå› ä¸ºè¿™é‡Œæ¶‰åŠåˆ°äº†ä¸€äº›ç§‘å­¦ä¸Šç½‘æ–¹é¢çš„çŸ¥è¯†ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä»å›½å†…æ‹‰å–åŸºç¡€é•œåƒï¼Œåœ¨åŸºç¡€é•œåƒåŸºç¡€ä¸Šæ„å»º`sglang:v0.4.9.post6-cu126`è¿™ä¸ªé•œåƒã€‚è¿™ä¸ªæ“ä½œæˆ‘ä¼šåœ¨æœ€åè¯´æ˜ã€‚

### 2.å¯åŠ¨ Docker å®¹å™¨

```shell
docker run --gpus all \
  --shm-size 32g \
  -p 30000:30000 -p 7860:7860 -p 8000:8000 \
  --ipc=host \
  -it mineru-sglang:latest \
  /bin/bash
```

æ‰§è¡Œè¯¥å‘½ä»¤åï¼Œæ‚¨å°†è¿›å…¥åˆ°Dockerå®¹å™¨çš„äº¤äº’å¼ç»ˆç«¯ï¼Œå¹¶æ˜ å°„äº†ä¸€äº›ç«¯å£ç”¨äºå¯èƒ½ä¼šä½¿ç”¨çš„æœåŠ¡ï¼Œæ‚¨å¯ä»¥ç›´æ¥åœ¨å®¹å™¨å†…è¿è¡ŒMinerUç›¸å…³å‘½ä»¤æ¥ä½¿ç”¨MinerUçš„åŠŸèƒ½ï¼Œä¹Ÿå¯ä»¥ç›´æ¥é€šè¿‡æ›¿æ¢`/bin/bash`ä¸ºæœåŠ¡å¯åŠ¨å‘½ä»¤æ¥å¯åŠ¨MinerUæœåŠ¡ï¼Œ

### 3.é€šè¿‡ Docker Compose ç›´æ¥å¯åŠ¨æœåŠ¡

OpenDataLabæä¾›äº† docker-compose.yaml æ–‡ä»¶ï¼Œå¯ä»¥é€šè¿‡è¯¥æ–‡ä»¶å¿«é€Ÿå¯åŠ¨MinerUæœåŠ¡ï¼š

```shell
wget -O docker-compose.yaml https://gcore.jsdelivr.net/gh/opendatalab/MinerU@master/docker/compose.yaml
```

è¯¥æ–‡ä»¶ä¸­åŒ…å«äº†MinerUçš„å¤šä¸ªæœåŠ¡é…ç½®ï¼Œå¯ä»¥æ ¹æ®éœ€è¦å¯åŠ¨æŒ‡å®šçš„æœåŠ¡ï¼š

```yaml
services:
  mineru-sglang-server:
    image: mineru-sglang:latest
    container_name: mineru-sglang-server
    restart: always
    profiles: ["sglang-server"]
    ports:
      - 30000:30000
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-sglang-server
    command:
      --host 0.0.0.0
      --port 30000
      # --enable-torch-compile  # You can also enable torch.compile to accelerate inference speed by approximately 15%
      # --dp-size 2  # If using multiple GPUs, increase throughput using sglang's multi-GPU parallel mode
      # --tp-size 2  # If you have more than one GPU, you can expand available VRAM using tensor parallelism (TP) mode.
      # --mem-fraction-static 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:30000/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]

  mineru-api:
    image: mineru-sglang:latest
    container_name: mineru-api
    restart: always
    profiles: ["api"]
    ports:
      - 8000:8000
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-api
    command:
      --host 0.0.0.0
      --port 8000
      # parameters for sglang-engine
      # --enable-torch-compile  # You can also enable torch.compile to accelerate inference speed by approximately 15%
      # --dp-size 2  # If using multiple GPUs, increase throughput using sglang's multi-GPU parallel mode
      # --tp-size 2  # If you have more than one GPU, you can expand available VRAM using tensor parallelism (TP) mode.
      # --mem-fraction-static 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]

  mineru-gradio:
    image: mineru-sglang:latest
    container_name: mineru-gradio
    restart: always
    profiles: ["gradio"]
    ports:
      - 7860:7860
    environment:
      MINERU_MODEL_SOURCE: local
    entrypoint: mineru-gradio
    command:
      --server-name 0.0.0.0
      --server-port 7860
      --enable-sglang-engine true  # Enable the sglang engine for Gradio
      # --enable-api false  # If you want to disable the API, set this to false
      # --max-convert-pages 20  # If you want to limit the number of pages for conversion, set this to a specific number
      # parameters for sglang-engine
      # --enable-torch-compile  # You can also enable torch.compile to accelerate inference speed by approximately 15%
      # --dp-size 2  # If using multiple GPUs, increase throughput using sglang's multi-GPU parallel mode
      # --tp-size 2  # If you have more than one GPU, you can expand available VRAM using tensor parallelism (TP) mode.
      # --mem-fraction-static 0.5  # If running on a single GPU and encountering VRAM shortage, reduce the KV cache size by this parameter, if VRAM issues persist, try lowering it further to `0.4` or below.
    ulimits:
      memlock: -1
      stack: 67108864
    ipc: host
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ "0" ]
              capabilities: [ gpu ]
```

é€šè¿‡è§‚å¯Ÿè¿™ä¸ªæ–‡ä»¶ï¼Œä¸éš¾å‘ç°MinerUä¸»è¦æä¾›ä¸‰ä¸ªæœåŠ¡ï¼š

#### 1. sglang-server æœåŠ¡

é€šè¿‡`vlm-sglang-client`åç«¯è¿æ¥`sglang-server`ï¼š

```shell
docker compose --profile sglang-server up -d
```



#### 2. Web API æœåŠ¡

```shell
docker compos --profile api up -d
```

åœ¨æµè§ˆå™¨ä¸­è®¿é—® `http://<server_ip>:8000/docs` æŸ¥çœ‹APIæ–‡æ¡£ã€‚

![](../images/mineru-web-api.png)

#### 3. Gradio WebUI æœåŠ¡

è¿™ä¸ªæœåŠ¡ä¸»è¦åŠŸèƒ½æ˜¯æä¾›äº†ä¸€ä¸ªå¯è§†åŒ–ç•Œé¢ï¼Œç”¨æ¥å¸®åŠ©ç”¨æˆ·ä½“éªŒMinerUæå–PDFã€å›¾ç‰‡ä¿¡æ¯çš„æ•ˆæœã€‚

```shell
docker compose --profile gradio up -d
```

åœ¨æµè§ˆå™¨ä¸­è®¿é—® `http://<server_ip>:7860` ä½¿ç”¨ Gradio WebUIã€‚

è®¿é—® `http://<server_ip>:7860/?view=api` ä½¿ç”¨ Gradio APIã€‚

åˆ°è¿™é‡Œæ•´ä¸ªMinerUæœåŠ¡å°±éƒ¨ç½²å®Œæˆå¯ä»¥æ­£å¸¸ä½¿ç”¨äº†ï¼Œåç»­æƒ³è¦å°† MinerU æŠ•å…¥ç”Ÿäº§ç¯å¢ƒä¸­è¿˜éœ€è¦åš3ä¸ªå·¥ä½œï¼š

1. å‹åŠ›æµ‹è¯•ï¼Œæµ‹è¯•æœ€å¤§å¹¶å‘é‡ï¼›
2. å¯¹ä¸Šä¼ ä¸´æ—¶æ–‡ä»¶è¿›è¡Œç®¡ç†ï¼Œè¿™æ¶‰åŠåˆ°äºŒæ¬¡å¼€å‘å·¥ä½œã€‚

å®Œæˆéƒ¨ç½²åªæ˜¯ç¬¬ä¸€æ­¥ï¼Œåç»­æƒ³è¦å°†MinerUé›†æˆè¿›ç°æœ‰çš„ç³»ç»Ÿï¼Œè¿˜éœ€è¦å¯¹æ¥å£è¿›è¡ŒäºŒæ¬¡å¼€å‘ï¼Œè‡³å°‘éœ€è¦ææ˜ç™½sglangçš„å·¥ä½œåŸç†ï¼Œç„¶åæ‰¾åˆ°mineru-apiè¿™ä¸ªå®¹å™¨æœåŠ¡çš„ä»£ç ï¼Œè¿™æ ·æ‰èƒ½ç”±äºŒæ¬¡å¼€å‘çš„åŸºç¡€ã€‚

### éšä¾¿è®²è®²

æƒ³è¦ä¿è¯MinerUæœåŠ¡æ­£å¸¸å¯åŠ¨ï¼Œé¦–å…ˆéœ€è¦ç¡®ä¿Cudaä¸ä½äº12.6ï¼Œä½†æ˜¯é—®é¢˜æ¥äº†ï¼Œæˆ‘å¹¶æ²¡æœ‰ä»å›½å†…çš„é•œåƒç«™ä¸Šæ‰¾åˆ°æ»¡è¶³ç‰ˆæœ¬è¦æ±‚çš„sglangé•œåƒã€‚docker.ioé•œåƒç«™å€’æ˜¯æœ‰ï¼Œä½†æ˜¯è¿™ä¸ªæ‹‰å–é€Ÿåº¦å°±ä¸€è¨€éš¾å°½äº†ï¼Œæ‰€ä»¥æˆ‘å°è¯•è‡ªè¡Œæ„å»ºsglangé•œåƒã€‚

é¦–å…ˆï¼Œä»Dockerfileä¸­ä¸éš¾åˆ¤æ–­å‡ºï¼Œä½¿ç”¨`apt` è¿›è¡ŒåŒ…ç®¡ç†ï¼Œä¸éš¾åˆ¤æ–­å‡ºè¿™æ˜¯ä¸€ä¸ªåŸºäºUbuntuæˆ–Debiançš„æ“ä½œç³»ç»Ÿï¼Œä»docker.ioé•œåƒç«™ä¸­æŸ¥æ‰¾åˆ°äº†å¯¹åº” tag ä¸º `v0.4.9.post6-cu126` é•œåƒçš„æ“ä½œç³»ç»Ÿç‰ˆæœ¬ä¸º Ubuntu 22.04ï¼Œå› æ­¤å¯ä»¥ç›´æ¥å°†å…¶ä½œä¸ºåŸºç¡€é•œåƒï¼ŒDockerfileå¦‚ä¸‹ï¼š

```dockerfile
# åŸºç¡€é•œåƒï¼šCUDA 12.6 + Ubuntu 22.04
FROM swr.cn-north-4.myhuaweicloud.com/ddn-k8s/docker.io/nvidia/cuda:12.6.3-cudnn-devel-ubuntu22.04

# è®¾ç½®ç¯å¢ƒå˜é‡
ENV DEBIAN_FRONTEND=noninteractive \
    TZ=Asia/Shanghai \
    PIP_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple

# æ¢æº & å®‰è£…åŸºç¡€ä¾èµ–
RUN sed -i 's/archive.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.list && \
    sed -i 's/security.ubuntu.com/mirrors.tuna.tsinghua.edu.cn/g' /etc/apt/sources.list && \
    apt-get update && apt-get install -y \
    git \
    curl \
    wget \
    build-essential \
    python3 \
    python3-pip \
    python3-venv \
    ninja-build \
    cmake \
    libnuma1 \
    libglib2.0-0 && \
    && rm -rf /var/lib/apt/lists/*

# å‡çº§ pip
RUN python3 -m pip install --upgrade pip setuptools wheel

# å…‹éš† sglang æºç 
WORKDIR /workspace
# RUN git clone https://gitee.com/mirrors/sglang
COPY sglang-v0.4.9.post6 /workspace/sglang
WORKDIR /workspace/sglang

# åˆ‡æ¢åˆ°ç¨³å®šç‰ˆæœ¬ï¼ˆv0.4.9.post6ï¼‰
# RUN git checkout v0.4.9.post6

# å®‰è£…ä¾èµ–å¹¶æ„å»º
RUN pip install -e "python[all]"

# é»˜è®¤å¯åŠ¨äº¤äº’å¼ shell
CMD ["/bin/bash"]
```

è¿™é‡Œæˆ‘æ˜¯ç›´æ¥å°†å¯¹åº”ç‰ˆæœ¬çš„sglangæºç ä¸‹è½½åˆ°äº†æœ¬åœ°ï¼Œå› ä¸ºå®¹å™¨å†…éƒ¨æ²¡æœ‰è®¾ç½®giteeçš„DNSï¼Œè¿™é‡Œä¹Ÿå¯ä»¥åœ¨æ‰§è¡Œ`docker build`å‘½ä»¤æ—¶æŒ‡å®šDNSæœåŠ¡å™¨ï¼Œä¹Ÿå¯ä»¥é€šè¿‡æˆ‘çš„æ–¹å¼ï¼Œä¸è¿‡éœ€è¦å¯¹åº”ä¿®æ”¹Dockerfileå†…å®¹ã€‚

å¼€å§‹æ„å»ºï¼š

```shell
docker build -t sglang:v0.4.9.post6-cu126 .
```

æ„å»ºå¥½ä¹‹åï¼Œå°±åšå¥½äº† MinerU çš„åŸºç¡€é•œåƒï¼Œå°±å¯ä»¥å¼€å§‹æ„å»ºäº†ã€‚

é‡åˆ°ä»»ä½•é—®é¢˜ï¼Œå…ˆç”¨ `docker logs -f` é…åˆä¸€äº›ç‚¹ç‚¹ç‚¹æ“ä½œæ¥çœ‹çœ‹æ—¥å¿—ï¼Œé€šè¿‡æ—¥å¿—å¯ä»¥è§£å†³å¾ˆå¤šé—®é¢˜ã€‚

ä¸å¤¸å¼ åœ°è¯´ï¼Œæ—¥å¿—åˆ†æèƒ½åŠ›æ˜¯å®æ–½ã€è¿ç»´å·¥ä½œä¸­çš„ä¸€å¤§åˆ©å™¨ã€‚

